# ai_agent/rag.py
# -*- coding: utf-8 -*-
import os
import re
from datetime import datetime
from typing import Dict, Any, List, Tuple, Optional, Union

import numpy as np
import pandas as pd
from dateutil import tz
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel, cosine_similarity
import google.generativeai as genai
from pathlib import Path

from config import GOOGLE_API_KEY, GEN_MODEL, POLICY_CSV, LOCAL_TZ, RAG_TOP_K_DEFAULT
from prompts import RAG_SYSTEM, RAG_DETAIL

from dotenv import load_dotenv
load_dotenv(override=True)

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
POLICY_CSV = os.path.join(BASE_DIR, "data", "930_preprocessed.csv")

class RAGRunner:
    """
    ê°œì„ ëœ TF-IDF ê¸°ë°˜ ë¡œì»¬ RAG + Gemini ë‹µë³€
    - í–¥ìƒëœ ê²€ìƒ‰ í’ˆì§ˆ (ë‹¤ì–‘ì„± í™•ë³´, ì¤‘ë³µ ì œê±°)
    - ì •í™•í•œ ë©€í‹°í„´ ìƒíƒœ ê´€ë¦¬
    - ê°œì„ ëœ ë²ˆí˜¸ ì„ íƒ ë¡œì§ (ì™„ì „ ì¬êµ¬ì„±)
    """

    RESET_PHRASES = ("ìƒë‹´ ì¢…ë£Œ", "ì¢…ë£Œ", "ê·¸ë§Œ", "ìƒˆë¡œ ì‹œì‘", "ì´ˆê¸°í™”")

    INTENT_SLOTS = {
        "deadline": ["deadline"],
        "overview": ["business_overview"],
        "eligibility": ["eligibility_content"],
        "amount": ["amount"],
        "method": ["application_method"],
        "contact": ["contact_info", "phone", "org_dept", "agency"],
        "link": ["link", "url"],
    }

    SYS_PROMPT: str = RAG_SYSTEM
    DETAIL_PROMPT: str = RAG_DETAIL

    def __init__(
        self,
        top_k: int = RAG_TOP_K_DEFAULT,
        initial_state: Optional[Dict[str, Any]] = None,
        csv_path: Optional[str | Path] = None,
        model_name: Optional[str] = None,
    ):
        # LLM ì„¤ì •
        if not GOOGLE_API_KEY:
            raise RuntimeError("GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤ (.env ë˜ëŠ” í™˜ê²½ë³€ìˆ˜).")
        genai.configure(api_key=GOOGLE_API_KEY)
        self.model_name = model_name or GEN_MODEL

        # ë°ì´í„° & ì¸ë±ìŠ¤ ì¤€ë¹„
        self.csv_path: Path = Path(csv_path) if csv_path else Path(POLICY_CSV)
        self.df = self._load_df(self.csv_path)
        self.docs = [self._build_doc_row(r) for _, r in self.df.iterrows()]
        
        # ê°œì„ ëœ TF-IDF ì„¤ì • (ë” ë„“ì€ ë²”ìœ„, ë‹¤ì–‘ì„± í™•ë³´)
        self.vectorizer = TfidfVectorizer(
            analyzer="char",
            ngram_range=(1, 4),  # 1~4ê¸€ì n-gramìœ¼ë¡œ í™•ì¥
            min_df=1,
            max_df=0.95,  # ë„ˆë¬´ í”í•œ ë‹¨ì–´ ì œê±°
            max_features=200_000,  # íŠ¹ì„± ìˆ˜ ì¦ê°€
            sublinear_tf=True,  # TF ì •ê·œí™”
        )
        self.tfidf = self.vectorizer.fit_transform(self.docs)

        # tz
        self.local_tz = tz.gettz(LOCAL_TZ)

        # ë©€í‹°í„´ ìƒíƒœ - ì™„ì „íˆ ì¬êµ¬ì„±ëœ êµ¬ì¡°
        self.state = {
            "selected_idx": None,  # í˜„ì¬ ì„ íƒëœ ì •ì±… ì¸ë±ìŠ¤
            "candidates": [],  # ê²€ìƒ‰ í›„ë³´ ë¦¬ìŠ¤íŠ¸ (ì‹¤ì œ ì¸ë±ìŠ¤)
            "candidate_display_map": {},  # {í‘œì‹œë²ˆí˜¸: ì‹¤ì œì¸ë±ìŠ¤}
            "pending_selection": False,  # ì‚¬ìš©ì ì„ íƒ ëŒ€ê¸° ì¤‘ì¸ì§€
            "last_reset": None,
            "detail_welcome": True,
            "last_query": "",
        }
        if initial_state:
            self.load_state(initial_state)

        self.top_k = top_k

    # ---------- ìƒíƒœ ì§ë ¬í™” ----------
    def save_state(self) -> Dict[str, Any]:
        """í˜„ì¬ ë©€í‹°í„´ ìƒíƒœë¥¼ dictë¡œ ë°˜í™˜"""
        return dict(self.state)

    def load_state(self, state: Dict[str, Any]) -> None:
        """ì™¸ë¶€ì—ì„œ ë¶ˆëŸ¬ì˜¨ ìƒíƒœë¥¼ í˜„ì¬ ì¸ìŠ¤í„´ìŠ¤ì— ë°˜ì˜"""
        for k in self.state.keys():
            if k in state:
                self.state[k] = state[k]

    # ---------- ë°ì´í„°/ì „ì²˜ë¦¬ ----------
    @staticmethod
    def _norm_date(x: str) -> str:
        x = str(x).strip()
        if not x or x.lower() in ["nan", "none"]:
            return ""
        x = x.replace(".", "-").replace("/", "-")
        try:
            return datetime.fromisoformat(x[:10]).date().isoformat()
        except Exception:
            return x

    def _load_df(self, path: Path) -> pd.DataFrame:
        df = pd.read_csv(path)
        df = df.drop("index", axis=1, errors="ignore")
        if "deadline" in df.columns:
            df["deadline"] = df["deadline"].map(self._norm_date)
        return df

    @staticmethod
    def _build_doc_row(row: pd.Series) -> str:
        link = row["link"] if str(row.get("link", "")).strip() else row.get("url", "")
        return (
            f"[ì •ì±…ëª…]{row.get('title','')} [ì§€ì—­]{row.get('region','')} "
            f"[ê¸°ê´€]{row.get('agency','')} [íƒœê·¸]{row.get('tag','')} [ë§ˆê°]{row.get('deadline','')}\n"
            f"[ê°œìš”]{row.get('business_overview','')}\n"
            f"[ëŒ€ìƒ]{row.get('eligibility_content','')}\n"
            f"[ì‹ ì²­]{row.get('application_method','')}\n"
            f"[ì—°ë½]{row.get('contact_info','')} {row.get('phone','')}\n"
            f"[ë§í¬]{link}"
        )

    # ---------- ê°œì„ ëœ ê²€ìƒ‰ ----------
    def _search(self, query: str, top_n: Optional[int] = None, diversity_weight: float = 0.3) -> Tuple[List[int], np.ndarray]:
        """ê°œì„ ëœ ê²€ìƒ‰: ë‹¤ì–‘ì„±ê³¼ ê´€ë ¨ì„±ì„ ëª¨ë‘ ê³ ë ¤"""
        top_n = top_n or self.top_k
        
        # ì¿¼ë¦¬ í† í° ì¶”ì¶œ
        tokens = re.findall(r"[ê°€-í£A-Za-z0-9]+", query)
        
        # ë©”íƒ€ë°ì´í„° ë¶€ìŠ¤íŒ… (ê¸°ì¡´ ë¡œì§ ê°œì„ )
        booster: List[str] = []
        query_boost_factor = 1.0
        
        if tokens:
            for col in ["title", "agency", "region", "tag"]:
                if col in self.df.columns:
                    # ì •í™• ë§¤ì¹­ê³¼ ë¶€ë¶„ ë§¤ì¹­ êµ¬ë¶„
                    exact_mask = self.df[col].astype(str).str.lower().str.contains(
                        "|".join([f"\\b{t.lower()}\\b" for t in tokens]), 
                        case=False, na=False, regex=True
                    )
                    partial_mask = self.df[col].astype(str).str.contains(
                        "|".join(tokens), case=False, na=False
                    )
                    
                    if exact_mask.any():
                        booster += self.df.loc[exact_mask, col].astype(str).head(2).tolist()
                        query_boost_factor = 2.0
                    elif partial_mask.any():
                        booster += self.df.loc[partial_mask, col].astype(str).head(3).tolist()
                        query_boost_factor = 1.5

        # ë¶€ìŠ¤íŒ…ëœ ì¿¼ë¦¬
        q_boost = query + (" " + " ".join(booster) if booster else "")
        
        # TF-IDF ìœ ì‚¬ë„ ê³„ì‚°
        q_vec = self.vectorizer.transform([q_boost])
        sims = cosine_similarity(q_vec, self.tfidf).flatten()
        
        # ë¶€ìŠ¤íŒ… ì ìš©
        sims *= query_boost_factor
        
        # ì´ˆê¸° í›„ë³´ ì„ ì • (ë” ë§ì´)
        candidate_count = min(top_n * 3, len(sims))
        initial_idxs = sims.argsort()[-candidate_count:][::-1]
        
        # ë‹¤ì–‘ì„±ì„ ê³ ë ¤í•œ ìµœì¢… ì„ ì •
        final_idxs = self._diversify_results(initial_idxs, sims, top_n, diversity_weight)
        
        return final_idxs, sims

    def _diversify_results(self, candidates: List[int], sims: np.ndarray, top_n: int, diversity_weight: float) -> List[int]:
        """ê²°ê³¼ ë‹¤ì–‘ì„± í™•ë³´"""
        if len(candidates) <= top_n:
            return candidates.tolist()
        
        selected = [candidates[0]]  # ìµœê³  ìœ ì‚¬ë„ëŠ” ë°˜ë“œì‹œ í¬í•¨
        remaining = candidates[1:].tolist()
        
        while len(selected) < top_n and remaining:
            best_idx = None
            best_score = -1
            
            for idx in remaining:
                # ê´€ë ¨ì„± ì ìˆ˜
                relevance_score = sims[idx]
                
                # ë‹¤ì–‘ì„± ì ìˆ˜ (ì„ íƒëœ ê²ƒë“¤ê³¼ì˜ ì°¨ì´)
                diversity_score = 0
                for sel_idx in selected:
                    # ì§€ì—­, ê¸°ê´€, íƒœê·¸ ë“±ì˜ ì°¨ì´ë¥¼ ì ìˆ˜í™”
                    diversity_score += self._calculate_diversity(idx, sel_idx)
                
                diversity_score /= len(selected)
                
                # ìµœì¢… ì ìˆ˜ (ê´€ë ¨ì„± + ë‹¤ì–‘ì„±)
                final_score = (1 - diversity_weight) * relevance_score + diversity_weight * diversity_score
                
                if final_score > best_score:
                    best_score = final_score
                    best_idx = idx
            
            if best_idx is not None:
                selected.append(best_idx)
                remaining.remove(best_idx)
            else:
                break
        
        return selected

    def _calculate_diversity(self, idx1: int, idx2: int) -> float:
        """ë‘ ì •ì±… ê°„ì˜ ë‹¤ì–‘ì„± ì ìˆ˜ ê³„ì‚°"""
        row1, row2 = self.df.loc[idx1], self.df.loc[idx2]
        
        diversity = 0
        # ì§€ì—­ì´ ë‹¤ë¥´ë©´ +1
        if str(row1.get('region', '')).strip() != str(row2.get('region', '')).strip():
            diversity += 1
        # ê¸°ê´€ì´ ë‹¤ë¥´ë©´ +1  
        if str(row1.get('agency', '')).strip() != str(row2.get('agency', '')).strip():
            diversity += 1
        # íƒœê·¸ê°€ ë‹¤ë¥´ë©´ +0.5
        if str(row1.get('tag', '')).strip() != str(row2.get('tag', '')).strip():
            diversity += 0.5
        
        return diversity / 2.5  # ì •ê·œí™”

    def _get_search_results(self, query: str, top_n: Optional[int] = None) -> List[int]:
        """ê²€ìƒ‰ ê²°ê³¼ë§Œ ë°˜í™˜ (ê°„ë‹¨í•œ ë²„ì „)"""
        idxs, _ = self._search(query, top_n=top_n)
        return idxs

    # ---------- ì˜ë„/ì»¨í…ìŠ¤íŠ¸ ----------
    @staticmethod
    def _parse_intent(q: str) -> str:
        x = q.lower()
        if any(k in x for k in ["ë§ˆê°", "ë§ˆê°ì¼", "deadline", "ì–¸ì œ", "ë°ë“œë¼ì¸", "ì–¸ì œê¹Œì§€"]): return "deadline"
        if any(k in x for k in ["ëŒ€ìƒ", "ìê²©", "ìš”ê±´", "eligibility"]): return "eligibility"
        if any(k in x for k in ["ê¸ˆì•¡", "ì–¼ë§ˆ", "ì§€ì›ê¸ˆ", "amount"]): return "amount"
        if any(k in x for k in ["ì‹ ì²­", "ì ‘ìˆ˜", "ë°©ë²•", "method", "how"]): return "method"
        if any(k in x for k in ["ì—°ë½", "ë¬¸ì˜", "ì „í™”", "ë‹´ë‹¹", "contact"]): return "contact"
        if any(k in x for k in ["ë§í¬", "ì›ë¬¸", "ìì„¸íˆ", "ì–´ë””ì„œ", "url"]): return "link"
        if any(k in x for k in ["ê°œìš”", "ìš”ì•½", "overview"]): return "overview"
        return "overview"

    @staticmethod
    def _build_detail_context(row: pd.Series) -> str:
        link = row["link"] if str(row.get("link", "")).strip() else row.get("url", "")
        return (
            f"[title]{row.get('title','')}\n"
            f"[business_overview]{row.get('business_overview','')}\n"
            f"[eligibility_content]{row.get('eligibility_content','')}\n"
            f"[link]{link}"
        )

    @staticmethod
    def _build_context(row: pd.Series, intent: str) -> str:
        link = row["link"] if str(row.get("link", "")).strip() else row.get("url", "")

        if intent == "deadline":
            main = f"[ë§ˆê°ì¼]{row.get('deadline') or 'ì •ë³´ ì—†ìŒ'}"
        elif intent == "eligibility":
            main = f"[ì§€ì›ëŒ€ìƒ]{row.get('eligibility_content') or 'ì •ë³´ ì—†ìŒ'}"
        elif intent == "amount":
            amt = row.get("amount")
            if isinstance(amt, (int, float)) and str(amt) != "nan":
                try:
                    amt = f"{float(amt):,.0f}ì›"
                except Exception:
                    pass
            main = f"[ì§€ì›ê¸ˆ]{amt or 'ì •ë³´ ì—†ìŒ'}"
        elif intent == "method":
            main = f"[ì‹ ì²­ë°©ë²•]{row.get('application_method') or 'ì •ë³´ ì—†ìŒ'}"
        elif intent == "contact":
            main = f"[ì—°ë½ì²˜]{row.get('contact_info','')} / {row.get('phone','')} ({row.get('org_dept') or row.get('agency')})"
        elif intent == "link":
            main = f"[ì›ë¬¸]{link or 'ì •ë³´ ì—†ìŒ'}"
        else:
            main = f"[ê°œìš”]{row.get('business_overview') or 'ì •ë³´ ì—†ìŒ'}"

        meta = (
            f"[ì •ì±…ëª…]{row.get('title','')} [ì§€ì—­]{row.get('region','')} [ê¸°ê´€]{row.get('agency','')}\n"
            f"[ë§ˆê°]{row.get('deadline','')}\n"
            f"[ë§í¬]{link}"
        )
        return f"{main}\n{meta}"

    # ---------- LLM í˜¸ì¶œ ----------
    def _llm_generate(self, prompt: str) -> str:
        resp = genai.GenerativeModel(self.model_name).generate_content(prompt)
        return (getattr(resp, "text", "") or "").strip()

    def _llm_answer_with_template(self, context_text: str, template: str) -> str:
        prompt = f"{template}\n\n[ì»¨í…ìŠ¤íŠ¸]\n{context_text}"
        return self._llm_generate(prompt)

    def _llm_answer(self, user_query: str, context_text: str, title: str, deadline: str) -> str:
        prompt = (
            f"{self.SYS_PROMPT}\n\n"
            f"[ì‚¬ìš©ì ì§ˆë¬¸]\n{user_query}\n\n"
            f"[ì»¨í…ìŠ¤íŠ¸]\n{context_text}\n"
        )
        return self._llm_generate(prompt)

    # ---------- ìƒíƒœ ê´€ë¦¬ ----------
    def reset(self):
        """ìƒíƒœ ì™„ì „ ì´ˆê¸°í™”"""
        self.state.update({
            "selected_idx": None,
            "candidates": [],
            "candidate_display_map": {},
            "pending_selection": False,
            "last_reset": datetime.now().isoformat(),
            "detail_welcome": True,
            "last_query": "",
        })

    def _extract_number_selection(self, text: str) -> Optional[int]:
        """ë²ˆí˜¸ ì„ íƒ ì¶”ì¶œ - ì™„ì „ ì¬êµ¬ì„±ëœ ë¡œì§"""
        patterns = [
            r"(\d+)ë²ˆ",
            r"ë²ˆí˜¸\s*(\d+)",
            r"\((\d+)\)",
            r"^(\d+)$",
            r"(\d+)\s*ì„ íƒ"
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text.strip())
            if match:
                num = int(match.group(1))
                # candidate_display_mapì—ì„œ ì‹¤ì œ ì¸ë±ìŠ¤ ì°¾ê¸°
                if num in self.state["candidate_display_map"]:
                    return self.state["candidate_display_map"][num]
        return None

    # ---------- í¼ë¸”ë¦­ ì—”ë“œí¬ì¸íŠ¸ - ì™„ì „ ì¬êµ¬ì„± ----------
    def answer(self, user_query: str, force_pick: bool = False, pick_idx: Optional[int] = None) -> Dict[str, Any]:
        """ì™„ì „íˆ ì¬êµ¬ì„±ëœ ë‹µë³€ ë¡œì§"""
        q = (user_query or "").strip()
        self.state["last_query"] = q

        # ì¢…ë£Œ ëª…ë ¹
        if any(p in q for p in self.RESET_PHRASES):
            self.reset()
            return {"route": "rag", "reply": "ìƒë‹´ì„ ì¢…ë£Œí–ˆìŠµë‹ˆë‹¤. ì¶”ê°€ë¡œ ê¶ê¸ˆí•œ ì •ì±…ì´ ìˆìœ¼ë©´ ë§ì”€í•´ì£¼ì„¸ìš”."}

        # ê°•ì œ ì„ íƒ (ì™¸ë¶€ì—ì„œ íŠ¹ì • ì •ì±… ì„ íƒ)
        if force_pick and pick_idx is not None and 0 <= pick_idx < len(self.df):
            self.state["selected_idx"] = pick_idx
            self.state["candidates"] = []
            self.state["candidate_display_map"] = {}
            self.state["pending_selection"] = False
            self.state["detail_welcome"] = True

        # 1ë‹¨ê³„: ì„ íƒ ëŒ€ê¸° ì¤‘ - ë²ˆí˜¸ ì…ë ¥ ì²˜ë¦¬
        if self.state["pending_selection"] and self.state["candidates"]:
            selected_idx = self._extract_number_selection(q)
            
            if selected_idx is not None:
                # ì„ íƒ ì™„ë£Œ
                self.state["selected_idx"] = selected_idx
                self.state["candidates"] = []
                self.state["candidate_display_map"] = {}
                self.state["pending_selection"] = False
                self.state["detail_welcome"] = True
                
                # ì„ íƒëœ ì •ì±…ì˜ ìƒì„¸ ì •ë³´ ì œê³µ
                row = self.df.loc[selected_idx]
                ctx = self._build_detail_context(row)
                answer = self._llm_answer_with_template(ctx, self.DETAIL_PROMPT)
                self.state["detail_welcome"] = False
                answer += "\n\nì¶”ê°€ë¡œ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ ë§ì”€í•´ì£¼ì„¸ìš”!"
                answer += "\n(ìƒë‹´ ì¢…ë£Œë¥¼ ì›í•˜ì‹œë©´ 'ìƒë‹´ ì¢…ë£Œ'ë¼ê³  ì…ë ¥í•´ ì£¼ì„¸ìš”.)"
                
                return {
                    "route": "rag",
                    "reply": answer,
                    "policy": {
                        "idx": int(selected_idx),
                        "title": row.get("title", ""),
                        "region": row.get("region", ""),
                        "deadline": row.get("deadline", ""),
                        "agency": row.get("agency", ""),
                        "link": row["link"] if str(row.get("link","")).strip() else row.get("url", ""),
                    },
                }
            else:
                # ì˜ëª»ëœ ì…ë ¥ - ë‹¤ì‹œ ì„ íƒ ìš”ì²­
                return {
                    "route": "rag",
                    "reply": (
                        "ì˜¬ë°”ë¥¸ ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”. ì˜ˆ: '1ë²ˆ', '2', '3ë²ˆ'\n\n"
                        "ë‹¤ì‹œ ê²€ìƒ‰í•˜ë ¤ë©´ ìƒˆë¡œìš´ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ê±°ë‚˜, "
                        "ìƒë‹´ì„ ì¢…ë£Œí•˜ë ¤ë©´ 'ìƒë‹´ ì¢…ë£Œ'ë¼ê³  ì…ë ¥í•´ ì£¼ì„¸ìš”."
                    ),
                }

        # 2ë‹¨ê³„: ì •ì±…ì´ ì´ë¯¸ ì„ íƒë¨ - ì„¸ë¶€ ì§ˆë¬¸ ì²˜ë¦¬
        if self.state["selected_idx"] is not None:
            row = self.df.loc[self.state["selected_idx"]]
            
            # ì²« ë°©ë¬¸ì‹œ í™˜ì˜ ë©”ì‹œì§€
            if self.state.get("detail_welcome", True):
                ctx = self._build_detail_context(row)
                answer = self._llm_answer_with_template(ctx, self.DETAIL_PROMPT)
                self.state["detail_welcome"] = False
            else:
                # ì„¸ë¶€ ì§ˆë¬¸ ì²˜ë¦¬
                intent = self._parse_intent(q)
                ctx = self._build_context(row, intent)
                answer = self._llm_answer(q, ctx, row.get("title",""), row.get("deadline",""))
                if intent == "deadline":
                    answer += "\n\nì´ë©”ì¼ ì•Œë¦¼ì„ ì„¤ì •í•´ ë“œë¦´ê¹Œìš”?"

            answer += "\n\n(ìƒë‹´ ì¢…ë£Œë¥¼ ì›í•˜ì‹œë©´ 'ìƒë‹´ ì¢…ë£Œ'ë¼ê³  ì…ë ¥í•´ ì£¼ì„¸ìš”.)"

            return {
                "route": "rag",
                "reply": answer,
                "policy": {
                    "idx": int(self.state["selected_idx"]),
                    "title": row.get("title", ""),
                    "region": row.get("region", ""),
                    "deadline": row.get("deadline", ""),
                    "agency": row.get("agency", ""),
                    "link": row["link"] if str(row.get("link","")).strip() else row.get("url", ""),
                },
            }

        # 3ë‹¨ê³„: ìƒˆë¡œìš´ ê²€ìƒ‰
        search_results = self._get_search_results(q, top_n=self.top_k)
        
        if not search_results:
            return {
                "route": "rag",
                "reply": "ê´€ë ¨ ì •ì±…ì„ ì°¾ì§€ ëª»í–ˆì–´ìš”. ì •ì±…ëª…ì„ ì¢€ ë” êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ ì£¼ì„¸ìš”.",
                "candidates": [],
            }

        # ê²€ìƒ‰ ê²°ê³¼ê°€ 1ê°œì¸ ê²½ìš° - ë°”ë¡œ ì„ íƒ
        if len(search_results) == 1:
            self.state["selected_idx"] = search_results[0]
            self.state["candidates"] = []
            self.state["candidate_display_map"] = {}
            self.state["pending_selection"] = False
            self.state["detail_welcome"] = True
            
            # ë°”ë¡œ ìƒì„¸ ì •ë³´ ì œê³µí•˜ì§€ ì•Šê³  ë‹¤ìŒ ë‹µë³€ì—ì„œ ì²˜ë¦¬í•˜ë„ë¡
            return self.answer("", force_pick=False, pick_idx=None)

        # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—¬ëŸ¬ê°œì¸ ê²½ìš° - ì„ íƒì§€ ì œê³µ
        self.state["candidates"] = search_results
        self.state["candidate_display_map"] = {i+1: idx for i, idx in enumerate(search_results)}
        self.state["pending_selection"] = True
        self.state["selected_idx"] = None  # ì•„ì§ ì„ íƒë˜ì§€ ì•ŠìŒ
        
        # ì„ íƒì§€ í‘œì‹œ
        preview_lines = []
        for display_num, real_idx in self.state["candidate_display_map"].items():
            row = self.df.loc[real_idx]
            marker = "ğŸ† " if display_num == 1 else "   "  # ì²« ë²ˆì§¸ëŠ” ê°€ì¥ ê´€ë ¨ì„± ë†’ìŒ
            preview_lines.append(
                f"{marker}{display_num}ë²ˆ: {row.get('title', '')} (ì§€ì—­: {row.get('region', '')}, ë§ˆê°: {row.get('deadline', 'ì •ë³´ì—†ìŒ')})"
            )
        
        preview = "\n".join(preview_lines)
        return {
            "route": "rag",
            "reply": (
                "ê²€ìƒ‰ëœ ì •ì±…ë“¤ì…ë‹ˆë‹¤. ìì„¸íˆ ì•Œê³  ì‹¶ì€ ì •ì±…ì˜ ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”:\n\n"
                f"{preview}\n\n"
                "â€» 1ë²ˆì´ ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ìŠµë‹ˆë‹¤.\n"
                "â€» ìƒë‹´ ì¢…ë£Œë¥¼ ì›í•˜ì‹œë©´ 'ìƒë‹´ ì¢…ë£Œ'ë¼ê³  ì…ë ¥í•´ ì£¼ì„¸ìš”."
            ),
            "candidates": search_results,
        }

    # ê²€ìƒ‰ ê²°ê³¼ë§Œ ë³´ê³  ì‹¶ì„ ë•Œ
    def search(self, query: str, k: Optional[int] = None) -> List[Dict[str, Any]]:
        """ê²€ìƒ‰ ê²°ê³¼ë§Œ ë°˜í™˜"""
        idxs, sims = self._search(query, top_n=k or self.top_k)
        out = []
        for i in idxs:
            out.append({
                "idx": int(i),
                "score": float(sims[i]),
                "title": self.df.loc[i, "title"],
                "region": self.df.loc[i, "region"],
                "deadline": self.df.loc[i, "deadline"],
                "agency": self.df.loc[i, "agency"],
            })
        return out